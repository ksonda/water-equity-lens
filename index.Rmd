---
title: "Demonstration of Demographic Indexing for Water Equity Lens"
author: 
- Kyle Onda^[kyle.onda@ondawater.org]
date: "`r Sys.Date()`"
output:   
  html_document:
    toc: true
    toc_float: true
    toc_depth: 5
    code_folding: hide
    fig_width: 8
    fig_height: 8
    theme: readable
---

```{r setup, message="FALSE", include="FALSE"}
set.seed(12432)
library(tidyverse)
library(sf)
library(mapview)
library(tidycensus)
library(skimr)
library(knitr)
library(leafsync)
library(corrplot)
library(zoo)
library(missForest)
census_api_key("b25f8b1b7bf10561c9cbc3a20a4d2572677f1f05")
options(tigris_use_cache = TRUE)

```

## Introduction

There is a large, diverse literature on creating indexes of what amounts to "Socioeconomic status" in spatial areas like neighborhoods. These indexes can then be used to investigate correlations between socioeconomics and health outcomes, infrastructure access, environmental exposures, or other variables, or target certain neighborhoods that seem particularly vulnerable for interventions. Many variables can be used to contribute to such an index. However, it is always difficult to choose which variables and how to weight them. For example, the USEPA EJSCREEN project tracks 6 demographic variables, but only uses two when constructing demographic indices to weight neighborhoods for an equity- weighting of environmental exposures: a simple average of % of population low-ioncome and % population "minority" (nonwhite alone/nonhispanic). One method that has been popular in social science and public health policy has been [Principal Components Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis) (PCA). See [this study](https://academic.oup.com/heapol/article/21/6/459/612115) for a foundational example. PCA creates linear combinations of sets of variables that explain the maximum amount of overall variance in the complete dataset. This amounts to weighting the variables that have the widest spread and that covary with other variables. In this way, any arbitrary combination of variables of interest to policymakers/planners/analysts can be chosen, and a linear combination of them constructed for use as a single or multiple indices in an automated manner. This approach has the added value of being customizable for different communities, where different axes of inequity may be more or less important or impactful than in other communities. 

## Data sources

In the United States, typically this activity has been done to identify regions with socioeconomic correlations with cancer incidence. The typical source for variables has been the U.S Census American Community Survey, which includes some detailed demographic information about race/ethnicity, education levels, income, occupation, and housing quality, among other topics. 

Two or more of the following variables are often used:

* % of households living below 200% of the Federal Poverty Level 
* % of population of age >=25 with <= grade 12 education
* % of households nonwhite and nonhispanic (i.e. "% minority")
* Median household income
* per capita income
* % population on public assistance (SSI Disability, TANF, etc)
* median monthly rent
* median value of owner-occupied housing
* % population in owner-occupied housing
* % population with "blue collar jobs"
* Over 16 unemployment rate
* % Households with more than 1.5 person per room
* % Households without complete plumbing
* percent HH "linguistically isolated (no people speak english "very well" or better)
* % HH with no vehicle available.
* % single-parent families

Some studies using them are listed below:

* [Wheeler DC, Czarnota J, Jones RM (2017) Estimating an area-level socioeconomic status index and its association with colonoscopy screening adherence. PLOS ONE 12(6): e0179272.](https://doi.org/10.1371/journal.pone.0179272)

* [Yang J, Schupp CW, Harrati A, Clarke C, Keegan THM, Gomez SL. 
Developing an area-based socioeconomic measure from American Community Survey data.  
Cancer Prevention Institute of California, Fremont, California. 2014](https://cancerregistry.ucsf.edu/sites/g/files/tkssra1781/f/wysiwyg/Yang%20et%20al.%202014_CPIC_ACS_SES_Index_Documentation_3-10-2014.pdf)

* [Yu M, Tatalovich Z, Gibson JT, Cronin KA. Using a composite index of socioeconomic status to investigate health disparities while protecting the confidentiality of cancer registry data. Cancer Causes Control. 2014 Jan;25(1):81-92](https://pubmed.ncbi.nlm.nih.gov/24178398)

* [Yost, K., Perkins, C., Cohen, R. et al. Socioeconomic status and breast cancer incidence in California for different race/ethnic groups. Cancer Causes Control 12, 703â€“711 (2001)](https://doi.org/10.1023/A:1011240019516)

* [Kieger N. et al., Geocoding and Monitoring of US Socioeconomic Inequalities in Mortality and Cancer Incidence: Does the Choice of Area-based Measure and Geographic Level Matter? The Public Health Disparities Geocoding Project, American Journal of Epidemiology 156(5), 471-482 (2002)](https://doi.org/10.1093/aje/kwf068)

* [Robert Graham Center Social Deprivation Index](https://www.graham-center.org/rgc/maps-data-tools/sdi/social-deprivation-index.html)

## The workflow

First, we take an example service area boundary. In this case the Newark Water Department.This comes from an external API but could be read from an arbitrary local or web location.

```{r, results="asis"}
#pws <- read_sf("C:/Users/kyleo/Downloads/pws.gpkg")
#newark <- filter(pws,PWSID=="NJ0714001")
newark <- read_sf("https://geoconnex.us/ref/pws/NJ0714001")
mapview(newark)

```

Then we find the relevant Census Block Groups (orange) or Tracts (green), first downloading the entire state and then subsetting to the utility service area (blue).

```{r census_boundaries}
bg <- get_acs(state = "NJ", geography = "block group", variables = c("B01001_001","B11016_001"), geometry = TRUE, output="wide") %>% st_transform(4326)
tr <- get_acs(state = "NJ", geography = "tract", variables = c("B01001_001","B11016_001"), geometry = TRUE, output="wide") %>% st_transform(4326)

bg1 <- st_intersects(bg,newark) %>% as.integer()
bg <- bg[which(bg1==1),]

tr1 <- st_intersects(tr,newark) %>% as.integer()
tr <- tr[which(tr1==1),]

mapview(newark, layer.name="Newark Water Department", map.types= "OpenStreetMap") +
  mapview(bg, alpha.regions=0, color="orange", col.regions="orange",lwd=2, layer.name="Block Groups", map.types= "OpenStreetMap") +
  mapview(tr, alpha.regions=0, color="green",col.regions="green", lwd=3, layer.name="Tracts", map.types= "OpenStreetMap") 

```

Now we download the necessary census data and match them to the appropriate census boundaries. 

```{r census_data}
vars <- tidycensus::load_variables(2019, "acs5", cache = TRUE)
cv <- c(pop_race_count = "B03002_001",
        pop_nonhispanic_white_alone = "B03002_003",
                 pop_educ_attainment_count = "B15003_001",
                 pop_educ_none = "B15003_002", #0
                 pop_educ_nursery = "B15003_003", #0
                 pop_educ_kindergarten = "B15003_004", #0
                 pop_educ_grade1 = "B15003_005", #1
                 pop_educ_grade2 = "B15003_006", #2
                 pop_educ_grade3 = "B15003_007", #3
                 pop_educ_grade4 = "B15003_008", #4
                 pop_educ_grade5 = "B15003_009", #5
                 pop_educ_grade6 = "B15003_010", #6
                 pop_educ_grade7 = "B15003_011", #7
                 pop_educ_grade8 = "B15003_012", #8
                 pop_educ_grade9 = "B15003_013", #9
                 pop_educ_grade10 = "B15003_014", #10
                 pop_educ_grade11 = "B15003_015", #11
                 pop_educ_grade12_nodiploma = "B15003_016", #11.5
                 pop_educ_HSdiploma = "B15003_017", #12
                 pop_educ_GED = "B15003_018", #12
                 pop_educ_college_less_1year = "B15003_019", #13
                 pop_educ_college_more_1year_nodegree = "B15003_020", #13.5
                 pop_educ_assoc = "B15003_021", #14
                 pop_educ_bachelor = "B15003_022", #16
                 pop_educ_master = "B15003_023", #18
                 pop_educ_prof = "B15003_024", #19
                 pop_educ_doc = "B15003_025", # 21
                 poverty_level_total = "C17002_001",
                 poverty_level_gr_200FPL = "C17002_008" ,
                 hh_income_20ptile = "B19080_001",
                 hh_income_median = "B19013_001",
                 pop_hh_income_assistance_total = "B09010_001",
                 pop_in_hh_with_income_assistance = "B09010_002",
                 per_capita_income = "B19301_001",
                 pop_labor_force = "B23025_001",
                 pop_unemployed = "B23025_005",
                 housing_units_count = "B25002_001",
                 housing_units_vacant = "B25002_003",
                 housing_units_occupied = "B25002_002",
                 pop_units_count = "B25033_001",
                 pop_owner_occupied_units = "B25033_002",
                 pop_rental_units = "B25033_008",
                 housing_units_plumbing_count = "B25050_001",
                 housing_units_plumbing_complete = "B25050_002",
                 rent_median = "B25058_001",
                 median_gross_rent_percent_hh_income = "B25071_001",
                 home_value_median = "B25077_001",
                 hh_owner_occupied = "B25014_002",
                 hh_owner_occupied_1.5_2_perRoom = "B25014_006",
                 hh_owner_occupied_gr2.0_perRoom = "B25014_007",
                 hh_renters = "B25014_008",
                 hh_renters_1.5_2_perRoom = "B25014_012",
                 hh_renters_gr2.0_perRoom = "B25014_013",
                 hh_lang_total = "C16002_001",
                 hh_lang_ltd_api ="C16002_010",
                 hh_lang_ltd_otherio = "C16002_007",
                 hh_lang_ltd_spanish = "C16002_004",
                 hh_lang_ltd_other = "C16002_013",
                 pop_age_total = "B01001_001",
                 pop_age_male_65_66 = "B01001_020",
                 pop_age_male_67_69 = "B01001_021",
                 pop_age_male_70_74 = "B01001_022",
                 pop_age_male_75_79 = "B01001_023",
                 pop_age_male_80_84 = "B01001_024",
                 pop_age_male_85up = "B01001_025",
                 pop_age_female_65_66 = "B01001_044",
                 pop_age_female_67_69 = "B01001_045",
                 pop_age_female_70_74 = "B01001_046",
                 pop_age_female_75_79 = "B01001_047",
                 pop_age_female_80_84 = "B01001_048",
                 pop_age_female_85up = "B01001_049",
                 occupation_total = "C24010_001",
                 occupation_sales_office_male = "C24010_027",
                 occupation_sales_office_female = "C24010_063",
                 occupation_service_male = "C24010_019",
                 occupation_service_female = "C24010_055",
                 occupation_protective_service_male = "C24010_021",
                 occupation_protective_service_female = "C24010_057",
                 occupation_natresource_male = "C24010_030",
                 occupation_natresource_female = "C24010_066",
                 occupation_prodtrans_male = "C24010_034",
                 occupation_prodtrans_female = "C24010_070",
                hh_vehicle_count = "B25044_001",
                hh_owner_noVehicle = "B25044_003",
                hh_renter_noVehicle = "B25044_010",
                families_total = "B11003_001",
                families_singleparent_female = "B11003_016",
                families_singleparent_male = "B11003_010"
        
    )


counties <- tidycensus::get_acs(year=2019,
                                geography = "county",
                                variables = "B01001_001",
                                geometry = TRUE)  %>% 
  sf::st_transform(4326) %>%
  dplyr::filter(lengths(sf::st_intersects(., newark)) > 0)

# Find FIPS code for relevant state and counties, make sure no duplicates
st <- unique(substr(counties$GEOID,1,2)) 
ct <- unique(substr(counties$GEOID,3,5))

data.tr <- get_acs(year=2019,
                              geography = "tract",
                              variables = cv,
                              geometry = TRUE,
                              state = st,
                              county=ct,
                              output="wide") %>%
  filter(GEOID %in% tr$GEOID)

 data.bg <- get_acs(year=2019,
                              geography = "block group",
                              variables = cv,
                              geometry = TRUE,
                              state = st,
                              county=ct,
                              output="wide") %>%
  filter(GEOID %in% bg$GEOID)

```

Now we construct the variables for our PCA at the Tract and Block Group level.

```{r variableConstruct}
pcaData.bg <- data.bg %>% 
  mutate(percBelow200FPL = 100*(1-poverty_level_gr_200FPLE/poverty_level_totalE),
         percEducLessHS = 100*(1-(pop_educ_HSdiplomaE +
                        pop_educ_GEDE +
                        pop_educ_college_less_1yearE +
                        pop_educ_college_more_1year_nodegreeE + 
                        pop_educ_assocE +
                        pop_educ_masterE +
                        pop_educ_profE +
                        pop_educ_docE)/pop_educ_attainment_countE),
         percMinority = 100*(1-pop_nonhispanic_white_aloneE/pop_race_countE),
         income_median = hh_income_medianE,
         income_20tile = hh_income_20ptileE,
         income_percapita = per_capita_incomeE,
         percAssistance = 100*pop_in_hh_with_income_assistanceE /pop_hh_income_assistance_totalE,
         rentMedian = rent_medianE,
         rentIncomeRatioMedian = median_gross_rent_percent_hh_incomeE,
         homeValuemedian = home_value_medianE,
         percHomeowners = 100*pop_owner_occupied_unitsE/pop_units_countE,
         percBlueCollar = 100*(occupation_sales_office_maleE +
                                 occupation_sales_office_femaleE +
                                 occupation_service_maleE +
                                 occupation_service_femaleE -
                                 occupation_protective_service_maleE -
                                 occupation_protective_service_femaleE +
                                 occupation_natresource_maleE +
                                 occupation_natresource_femaleE +
                                 occupation_prodtrans_maleE +
                                 occupation_prodtrans_femaleE)/occupation_totalE,
         percUnemployed=pop_unemployedE/pop_labor_forceE,
         percPlumbingComplete = housing_units_plumbing_completeE/housing_units_plumbing_countE,
         percFamiliesSingleParent = 100*(families_singleparent_femaleE + families_singleparent_maleE)/families_totalE,
         percHH_NoVehicle = 100*(hh_owner_noVehicleE+hh_renter_noVehicleE)/hh_vehicle_countE,
         percAgeOver64 = 100*(pop_age_male_65_66E + 
                                pop_age_male_67_69E +
                                pop_age_male_70_74E +
                                pop_age_male_75_79E +
                                pop_age_male_80_84E +
                                pop_age_male_85upE +
                                pop_age_female_65_66E + 
                                pop_age_female_67_69E +
                                pop_age_female_70_74E +
                                pop_age_female_75_79E +
                                pop_age_female_80_84E +
                                pop_age_female_85upE)/pop_age_totalE,
         percHH_LangIsolated = 100 * (hh_lang_ltd_apiE +
                                        hh_lang_ltd_otherioE +
                                        hh_lang_ltd_spanishE +
                                        hh_lang_ltd_otherE)/hh_lang_totalE,
         percHH_Crowded = 100 * (hh_owner_occupied_1.5_2_perRoomE +
                                   hh_owner_occupied_gr2.0_perRoomE +
                                   hh_renters_1.5_2_perRoomE +
                                   hh_renters_gr2.0_perRoomE)/(hh_owner_occupiedE + hh_rentersE)) %>%
  select(GEOID,percBelow200FPL:percHH_Crowded) %>%
  st_drop_geometry()

pcaData.tr <- data.tr %>% 
  mutate(percBelow200FPL = 100*(1-poverty_level_gr_200FPLE/poverty_level_totalE),
         percEducLessHS = 100*(1-(pop_educ_HSdiplomaE +
                        pop_educ_GEDE +
                        pop_educ_college_less_1yearE +
                        pop_educ_college_more_1year_nodegreeE + 
                        pop_educ_assocE +
                        pop_educ_masterE +
                        pop_educ_profE +
                        pop_educ_docE)/pop_educ_attainment_countE),
         percMinority = 100*(1-pop_nonhispanic_white_aloneE/pop_race_countE),
         income_median = hh_income_medianE,
         income_20tile = hh_income_20ptileE,
         income_percapita = per_capita_incomeE,
         percAssistance = 100*pop_in_hh_with_income_assistanceE /pop_hh_income_assistance_totalE,
         rentMedian = rent_medianE,
         rentIncomeRatioMedian = median_gross_rent_percent_hh_incomeE,
         homeValuemedian = home_value_medianE,
         percHomeowners = 100*pop_owner_occupied_unitsE/pop_units_countE,
         percBlueCollar = 100*(occupation_sales_office_maleE +
                                 occupation_sales_office_femaleE +
                                 occupation_service_maleE +
                                 occupation_service_femaleE -
                                 occupation_protective_service_maleE -
                                 occupation_protective_service_femaleE +
                                 occupation_natresource_maleE +
                                 occupation_natresource_femaleE +
                                 occupation_prodtrans_maleE +
                                 occupation_prodtrans_femaleE)/occupation_totalE,
         percUnemployed=pop_unemployedE/pop_labor_forceE,
         percPlumbingComplete = housing_units_plumbing_completeE/housing_units_plumbing_countE,
         percFamiliesSingleParent = 100*(families_singleparent_femaleE + families_singleparent_maleE)/families_totalE,
         percHH_NoVehicle = 100*(hh_owner_noVehicleE+hh_renter_noVehicleE)/hh_vehicle_countE,
         percAgeOver64 = 100*(pop_age_male_65_66E + 
                                pop_age_male_67_69E +
                                pop_age_male_70_74E +
                                pop_age_male_75_79E +
                                pop_age_male_80_84E +
                                pop_age_male_85upE +
                                pop_age_female_65_66E + 
                                pop_age_female_67_69E +
                                pop_age_female_70_74E +
                                pop_age_female_75_79E +
                                pop_age_female_80_84E +
                                pop_age_female_85upE)/pop_age_totalE,
         percHH_LangIsolated = 100 * (hh_lang_ltd_apiE +
                                        hh_lang_ltd_otherioE +
                                        hh_lang_ltd_spanishE +
                                        hh_lang_ltd_otherE)/hh_lang_totalE,
         percHH_Crowded = 100 * (hh_owner_occupied_1.5_2_perRoomE +
                                   hh_owner_occupied_gr2.0_perRoomE +
                                   hh_renters_1.5_2_perRoomE +
                                   hh_renters_gr2.0_perRoomE)/(hh_owner_occupiedE + hh_rentersE)) %>%
  select(GEOID,percBelow200FPL:percHH_Crowded) %>%
  st_drop_geometry()


```

Now, we inspect the distributions of the variables to see which ones may be problematic. It appears that the following variables are highly skewed and should be transformed:

* % Minority
* % houses with complete plumbing
* % Households in crowded positions (>= 1.5 people per room)

It also appears that the following variables are not available or otherwise highly missing at the block group level:

* % population on public assistance (100% missing)
* THe 20th percentile of HH income (100% missing)
* Median home value (11% missing)
* Median income (7% missing)

If clients are determined to use these variables, tract-level analysis may be necessary, which may not work for custom geographies that need to be assembled from smaller geographies than tracts.

We cannot use public assistance with Census Block Groups, but 20th percentile of income can be calculated from other means, and median home value can be imputed.

### Imputing missing data

We use a random forest missing value imputation algorithm (see [here](https://doi.org/10.1093/bioinformatics/btr597)) to fill in missing data for the purposes of later indexing. Compare median home values in the unimputed vs. imputed datasets

```{r impute, results="asis"}
imp.bg <- dplyr::select(pcaData.bg,-GEOID,-income_20tile,-percAssistance)
imp.bg <- missForest(imp.bg)
imp.bg <- imp.bg$ximp
imp.bg$GEOID <- pcaData.bg$GEOID

missing <- select(pcaData.bg,GEOID,homeValuemedian)
imputed <- select(imp.bg,GEOID,homeValuemedian)

imp.demo <- left_join(bg,missing,by="GEOID")
imp.demo <- left_join(imp.demo,imputed,by="GEOID")

map.miss <- mapview(imp.demo,zcol="homeValuemedian.x",layer.name="Median Home value (NA)")
map.imp <- mapview(imp.demo,zcol="homeValuemedian.y", layer.name="Median Home Value (imputed)")

sync(map.miss,map.imp)

```

### Alternative boundaries

With all missing data imputed, we can now demonstrate how U.S. Census data can be re-estimated for arbitrary larger geographies. Below, take the example of the City of Newark's [Neighborhood](https://data.ci.newark.nj.us/dataset/neighborhoods2013) boundaries, compared with Census Block Groups.

```{r otherbounds, results="asis"}
alt <- sf::read_sf("https://data.ci.newark.nj.us/dataset/bb616963-ea12-434e-96c1-526820517a66/resource/d59cbbb5-9762-4063-9c21-fc6fa3e1f787/download/newarkneighborhoods2013.geojson")

 mapview(bg, layer.name= "Census Block Groups") + mapview(alt, alpha.regions=0, col.regions="darkslategrey", lwd=3, color="darkslategrey", layer.name="Alt. Polygons (Neighborhoods)") + mapview(newark, alpha.regions=0, lwd=2, color="black", col.regions="black",layer.name = "Newark Water Service Area")

```
##### Reweighting for different polygons

In this case, Newarks alternative polygons seem to mostly be combinations of Census Block Groups, with minor discrepancies at borders. Other alternative polygons may be substantially different, so we implement a general weighted-area algorithm to reweight our census variables to the alternative polygon. The principle is the same as that documented [here](https://doi.org/10.1371/journal.pone.0245237.s003). 


First, we compute the area of the block groups (projecting to the appropriate state plane projection)
```{r weight}
bg <- bg %>% 
  st_transform(32111) %>% # project to NAD83/New Jersey Projection
  mutate(area_bg = st_area(.))# compute area
```

Then we compute the area of the alternative polygons (projecting to the appropriate state plane projection)

```{r weight}
alt <- alt %>% 
  st_transform(32111) %>% # project to NAD83/New Jersey Projection
  mutate(area_alt = st_area(.))# compute area
```

Now we compute the spatial intersection of the alternate geometry with the block groups

```{r intersect}
alt.bg <- sf::st_intersection(alt,bg)

alt.bg <- alt.bg %>% 
  mutate(area_alt_bg = st_area(.), #calculate area of intersection of block group and alternative polygon
         share_area = area_alt_bg/area_alt, #calcualte share of area of each block group in each custom polygon
         pop = share_area * B01001_001E, #calculate population of each intersection
         hh = share_area * B11016_001E) %>% #calcualte hh of each intersection
  group_by(Neighborhood) %>% #group calculations by alternate polygon
  mutate(alt_pop = sum(pop), # calculate population of alternate polygons
         alt_hh = sum(hh) #calculate hh in alternate polygons
         ) %>% 
  ungroup() %>% #ungroup calculations
  mutate(wgt_pop = pop/alt_pop, #calculate prop of population of alternate polygon represented by each intersection
         wgt_hh = hh/alt_hh) #calculate prop of hh of alternate polygon represented by each intersection



```
Now we can weight every variable by hh and pop weights as appropriate to come up with the alternative polygon measures.

```{r transform}
imp.bg.long <- pivot_longer(imp.bg,!GEOID,names_to = "var",values_to = "value")
imp.bg.long <- left_join(imp.bg.long,alt.bg,by="GEOID")
imp.bg.long$value <- imp.bg.long$value * imp.bg.long$wgt_hh
imp.bg.long <- select(imp.bg.long,Neighborhood,var,value)
imp.neigh.long <- imp.bg.long %>% 
  group_by(Neighborhood,var) %>% 
  summarise(value=sum(value))


alt_polygons <- alt %>% 
  left_join(imp.neigh.long,by="Neighborhood") %>%
  select(Neighborhood,var,value)

alt_polygons$alt_polygon_id <- alt_polygons$Neighborhood
alt_polygons <- select(alt_polygons,alt_polygon_id,var,value)

v <- as.data.frame(unique(alt_polygons$var))
v$units = c("USD",
            "USD",
            "USD",
            "%",
            "%",
            "%",
            "%",
            "%",
            "%",
            "%",
            "%",
            "%",
            "%",
            "%",
            "%",
            "ratio",
            "USD"
            )

colnames(v) <- c("var","units")

alt_polygons <- na.omit(alt_polygons)
alt_data <- st_drop_geometry(alt_polygons)
alt_data <- left_join(alt_data,v,by="var")
alt_data$value <- as.numeric(alt_data$value)
alt_polygons <- distinct(select(alt_polygons,alt_polygon_id))
alt_polygons <- st_transform(alt_polygons,4326)

bg_data <- pivot_longer(imp.bg,!GEOID,names_to = "var",values_to = "value")
bg_data <- left_join(bg_data,v,by="var")
bg_polygons <- select(bg,GEOID)
newark.p <- st_transform(newark,32111)
bg_polygons <- st_intersection(bg_polygons,newark.p)
bg_polygons <- select(bg_polygons,GEOID)
bg_polygons <- st_transform(bg_polygons,4326)


bg_data$var <- paste0("census_",bg_data$var)
alt_data$var <- paste0("census_",alt_data$var)

```
We do something similar with the block groups as bounded by the service area boundary now. 



```{r inspect}
# skim(pcaData.tr)
# skim(pcaData.bg)
```

With this knowledge, we conduct the PCA, first on all the available variables for Block Groups and for Tracts. Below, we report on the first three principal components of the PCA for the tracts and block groups.

```{r transform, warning=FALSE, message=FALSE}
# is.nan.data.frame <- function(x)
# do.call(cbind, lapply(x, is.nan))
# 
# pcaData.bg[is.nan(pcaData.bg)]<-NA
# x=select(pcaData.bg,-GEOID,-percAssistance, -income_20tile)

bg_data_wide <- bg_data %>% pivot_wider(id_cols=GEOID,names_from = var, values_from = value)
pca.matrix.bg <- bg_data_wide %>% select(-GEOID)
pca.bg <- prcomp(pca.matrix.bg, scale=TRUE, center=TRUE, na.action=na.omit, rank=3)
bg_data_wide$PC1 <- pca.bg$x[,1]
bg_data <- pivot_longer(bg_data_wide,!GEOID,names_to = "var",values_to = "value")


alt_data_wide <- alt_data %>% distinct(alt_polygon_id,var,.keep_all=TRUE) %>% pivot_wider(id_cols=alt_polygon_id,names_from = var, values_from = value)

pca.matrix.alt <- alt_data_wide %>% select(-alt_polygon_id)
pca.alt <- prcomp(pca.matrix.alt, scale=TRUE, center=TRUE, na.action=na.omit, rank=3)
alt_data_wide$PC1 <- pca.alt$x[,1]
alt_data <- pivot_longer(alt_data_wide,!alt_polygon_id,names_to = "var",values_to = "value")
v$var <- paste0("census_",v$var)
alt_data <- left_join(alt_data,v,by="var")

colnames(alt_polygons)[1]<-"geo_id"
colnames(bg_polygons)[1]<-"geo_id"
write_sf(alt_polygons,"finalData/alt_polygons.geojson")
write_sf(bg_polygons,"finaldata/bg_polygons.geojson")


overall <- left_join(bg_data,select(bg,GEOID,B01001_001E),by="GEOID")
overall <- st_as_sf(overall)
overall$area_bg <- st_area(overall)
overall <- st_intersection(overall,select(newark.p,id))
overall$area_intersection <- st_area(overall)
overall$area_share <- overall$area_intersection/overall$area_bg
overall$wgt <- (overall$area_share * overall$B01001_001E) / sum(bg$B01001_001E)
overall$value <- overall$value * overall$wgt

overall <- overall %>% st_drop_geometry() %>% group_by(var) %>% summarise(value=sum(value))

n <- newark %>% select(id)
colnames(n)[1]<-"geo_id"
write_sf(newark,"finaldata/overall_polygon.geojson")
```

#### Add other variables

Let's create a vector of all the other variables that might be there:

```{r}
year <- c(2019,2020)
var <- c("pillar1_hbi",
         "pillar1_ppi",
         "pillar1_affordability_score",
         "pillar1_cutoff",
         "pillar1_cap",
         "pillar1_connections_water",
         "pillar1_connections_sewer",
         "pillar2_workforce",
         "pillar2_diversity_1",
         "pillar2_diversity_2",
         "pillar2_procurement",
         "pillar2_training",
         "pillar2_park_distance",
         "pillar2_park_density",
         "pillar2_park_walk_access",
         "pillar2_waterfront_acess",
         "pillar2_public_facing",
         "pillar3_uri",
         "pillar3_breaks",
         "pillar3_sewer_failures",
         "pillar3_lead_lines",
         "pillar3_lead_line_replacement",
         "pillar3_proactive_maintenance",
         "pillar3_outreach",
         "pillar3_meetings",
         "pillar3_water_board",
         "pillar3_flooding",
         "pillar3_complaints"
         )

geo_type <- c("block_group","alternate","service_area")

geo_id <- unique(bg_data$GEOID)
geo_id <- as.data.frame(c(geo_id,unique(alt_data$alt_polygon_id)))
geo_id <- rbind(geo_id,"NJ0714001")

colnames(geo_id)[1] <- "geo_id"

pillars <- expand_grid(geo_id,year,var) 
pillars$geo_type <- "block_group"
pillars$geo_type[15345:16408] <- "alternate"
pillars$geo_type[16409:16520] <- "service_area"

pillars$units <- "%"
pillars$units[which(pillars$var %in% c("pillar1_hbi",
                                       "pillar2_workforce",
                                       "pillar2_public_facing",
                                       "pillar3_breaks",
                                       "pillar3_sewer_failures"))] <- "ratio"


pillars <- pillars %>% group_by(var,year) %>% mutate(value=runif(1))
pillars$value[which(pillars$units=="%")] <- 100*pillars$value[which(pillars$units=="%")]

pillars <- pillars %>% 
  arrange(geo_id,var,year) %>% 
  group_by(geo_id,var) %>% mutate(delta_percent = 100*(value - lag(value))/lag(value)) %>% ungroup()

pillars <- select(pillars,geo_id,geo_type,year,var,value,units,delta_percent)

pillars$units[which(pillars$var=="pillar1_affordability_score")] <- "character"
pillars$value[which(pillars$var=="pillar1_affordability_score")] <- sample(c("Low","Medium","High"),590,replace=TRUE)
pillars$delta_percent[which(pillars$units=="character")]<-NA

write_csv(pillars,"finalData/indicators.csv")

bg_data2 <- left_join(bg_data,v,by="var")

alt_data$geo_type <- "alternate"
alt_data$geo_id <- alt_data$alt_polygon_id
alt_data <- select(alt_data,geo_id,geo_type,var,value_units)

bg_data2$geo_type <- "block_group"
bg_data2$geo_id <- bg_data2$GEOID
bg_data2 <- select(bg_data2,geo_id,geo_type,var,value_units)

overall$geo_id <- "NJ0714001"
overall$geo_type <- "service_area"
overall$value <- as.numeric(overall$value)
overall2 <- left_join(overall,v,by="var")
overall2 <- select(overall2,geo_id,geo_type,var,value,units)

census <- bind_rows(bg_data2,alt_data,overall2)
census$year <- 2019
census <- select(census,geo_id,geo_type,year,var,value,units)

x = bg_data2 %>% filter(geo_type=="block_group" & year==2019) %>% pivot_wider(id_cols=geo_id,names_from = var, values_from = value) %>% arrange(geo_id) %>% select(-geo_id)
y = pillars %>% mutate(value=runif(n=16520)) %>% filter(geo_type=="block_group" & year == 2019)  %>% pivot_wider(id_cols=geo_id,names_from = var, values_from = value) %>% arrange(geo_id) %>% select(-geo_id)
c <- cor(x=x,y=y)
c <- as.data.frame(c)
c$census_var <- rownames(c)
c <- pivot_longer(c,cols=pillar1_affordability_score:pillar3_water_board ,names_to = "variable", values_to="corr")

write_csv(c,"finalData/correlations.csv")

write_csv(census,"finalData/census.csv")
```


## Results 

For tracts, we see that the first component alone explains 42% of the variance in the specified variables. Higher values on this component are associated with lower income measures, higher poverty, public assistance and unemployment, lower rents and housing values, more blue collar employment, higher proportions of minority groups, lower homeownership rates, less vehicle ownership, and higher prevalence of single-parent families, without being particularly informed by linguistic isolation, education levels, or housing crowdedness.

```{r, results="asis"}
kable(summary(pca.tr)$importance[1:3,1:3],digits=2)
kable(pca.tr$rotation,digits=2)
```

For block groups, we see that the first component alone explains only 29% of the variance in the specified variables (compared to 42% in the tract-level analysis). However, the way the variables contribute to the first component is similar to how they do in the tract-level analysis.

```{r, results="asis"}
kable(summary(pca.bg)$importance[1:3,1:3],digits=2)
kable(pca.bg$rotation,digits=2)
```

Below, we visualize how the first component (PC1) can be used as a multidimensional socioeconomic status/ deprivation index, that incorporates more information and yields different results than just using income or poverty levels or minority group prevalence. Tracts have less missing data than block groups, generally due to U.S. Census Bureau privacy controls that restrict reporting of certain cross-tabulations in small areas. Thus, the smaller the area, the fewer variables are suitable for use in constructing socioeconomic indexes.

```{r, results="asis"}
bg <- left_join(bg,pcaData.bg,by="GEOID")
tr <- left_join(tr,pcaData.tr,by="GEOID")
tr$PC1_allVars <- -tr$PC1_allVars

m.pc.bg <- mapview(bg,zcol="PC1_allVars", layer.name="Block Groups \n PC1") + mapview(newark,alpha.regions=0,col.regions="red",color="red",layer.name="Newark Water Dept.", lwd=2)
m.pov.bg <- mapview(bg,zcol="income_median", layer.name="Block Groups \n Median HH Income") + mapview(newark,alpha.regions=0,col.regions="red",color="red",layer.name="Newark Water Dept.", lwd=2)

m.pc.tr <- mapview(tr,zcol="PC1_allVars", layer.name="Tracts \n PC1") + mapview(newark,alpha.regions=0,col.regions="red",color="red",layer.name="Newark Water Dept.", lwd=2)
m.pov.tr <- mapview(tr,zcol="income_median", layer.name="Tracts \n Median HH Income") + mapview(newark,alpha.regions=0,col.regions="red",color="red",layer.name="Newark Water Dept.", lwd=2)

mapl <- sync(m.pc.bg, m.pov.bg, m.pc.tr, m.pov.tr)
mapl
```

## Using indexes and correlation indexes to create insights.

### Scaling variables by indexes.

Below we demonstrate how using an index can be used to highlight neighborhoods that users may be more interested in from an equity framework. For example, if the distribution of a problematic phenomenon such as taste complaints is randomly distributed, then from an equity perspective, one may wish to prioritize addressing these issues in the most socioeconomically burdened neighborhoods before less burdened neighborhoods.

We simulate tract-level taste complaints per household as a normally distributed random variable with a mean of 0.2 and a standard deviation of 0.1 and a minimum of 0, with no assumed correlation with any equity-related variable:

```{r taste, results="asis"}
set.seed(2354367)
tr$taste_complaints_perHH <- rnorm(n=130,mean=0.2, sd=0.1)
tr$taste_complaints_perHH[which(tr$taste_complaints_perHH<0)] <- 0
tr$PC1_allVars <- -tr$PC1_allVars

map.tr <- mapview::mapview(tr,zcol="taste_complaints_perHH", layer.name="Tracts \n Taste Compl per HH.")

map.pc <- mapview::mapview(tr,zcol="PC1_allVars", layer.name="Tracts \n Burden Index")

sync(map.pc, map.tr)


ggplot2::ggplot(data=tr, aes(x=-PC1_allVars,y=taste_complaints_perHH)) + geom_point() + geom_abline() + xlab("Equity Principal Component (higher = more burdened)")
```

As we can see above, there is no correlation between our simulated taste complaint indicator and the socioeconomic status index (scale reversed, so that higher numbers correspond to a more "burdened" area).

We can multiply the taste complaint indicator by the "burden" index to create a taste complaint scaled by burden that will highlight different areas to focus on than by focusing on the indicator alone:

```{r scale demo, results="asis"}
tr$taste_scaled <- tr$PC1_allVars* tr$taste_complaints_perHH

map.tr <- mapview::mapview(tr,zcol="taste_complaints_perHH", layer.name="Tracts \n Taste Compl per HH.")

map.pc <- mapview::mapview(tr,zcol="taste_scaled", layer.name="Taste complaints scaled by burden")

sync(map.pc, map.tr)

```

### Insights: most correlated variables

There are many sophisticated methods from the "machine learning" toolbox (e.g. stepwise regression algorithms, ridge regressions, LASSO, random forest models, ) that could serve to identify particular models based on sociodemographic/economic variables that most effectively predict values of equity/performance variables. However, it may be more straightforward to justify and communicate highlighting which sociodemographic variables are most linearly correlated with a variable of interest.

Let's simulate come equity indicators that are various functions of the socioeconomic variables:

```{r y_simuolate}
x <- tr[6:31] %>% 
  st_drop_geometry() %>% 
  na.aggregate()

pca <- pca.tr$x

y1 <- x$PC1 + rnorm(length(x$PC1),0,1)
y2 <- 0.5*x$PC1 + 0.5*x$PC2 + rnorm(length(x$PC1),0,1)
y3 <- 0.5*x$PC3 + 0.5*x$PC2 + rnorm(length(x$PC1),0,1)
```

Now we compute the correlation between each of these simulated indicators and all of the socioeconomic variables. Correlation is measured on a scale between -1 and 1, with values closer to 0 indicating less correlation. The table below shows how each of the three simulated equity indicators are correlated with each of the socioeconomic variables. For example, $y1$ is highly correlated with the percentage of the households below 200% of the Federal Poverty level, Single parent families, and households with no vehicle,  and strongly inversely correlated with income measures, home values, and home ownership rates. $y3$, on the other hand, is most highly correlated with lower levels of linguistic isolation and education levels below high school. This would enable a dynamic insight to be generated, where a user could select an equity indicator, and be shown any relevant descriptions or plots for any associated socioeconomic variables. 

```{r corr, results="asis"}
y <- as.data.frame(cbind(y1,y2,y3))
x <- tr[6:24] %>% 
  st_drop_geometry() %>% 
  na.aggregate()
c <- cor(x=x,y=y)

test <- cor.mtest(cbind(y,x))$p[1:3,4:22]

corrplot(c,
  method = "number",
  type = "full",
  order="original"# show only upper side
)
```
Saving our data at the tract and block group level
```{r save}
sf::write_sf(bg,"data/census_blockgroup_newark.geojson")
sf::write_sf(tr,"data/census_tract_newark.geojson")
sf::write_sf(newark,"data/service_area_newark.geojson")
```
